import openai
import streamlit as st
import matplotlib.pyplot as plt

import pandas as pd
from datetime import datetime
from google_sheet import append_checkin_to_sheet, get_all_checkins
from checkin_crypto import encrypt_checkin, decrypt_checkin
from openai import OpenAI

import json
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

from PIL import Image, ImageDraw, ImageFont
import requests
from io import BytesIO

import random

def build_past_context(user_email: str, max_checkins: int = 5) -> str:
    """Return a short paragraph with the userâ€™s most recent answers."""
    df = load_user_checkins(user_email)
    if df is None or df.empty:
        return "No history yet."
    latest = df.sort_values("date").tail(max_checkins)

    out_lines = []
    for _, row in latest.iterrows():
        pieces = []
        for cat in canvas_qs_pool.keys():      # keep category order
            pieces.append(
                f"{cat}: {row.get(f'{cat} Q1','')} | {row.get(f'{cat} Q2','')}"
            )
        out_lines.append(f"{row['date']}: " + " || ".join(pieces))
    return "\n".join(out_lines)


def fetch_dynamic_qs_openai(user_email: str) -> dict:
    """
    Ask OpenAI for 5Ã—2 questions *and* their help tips.
    Format expected from the model (strict JSON, no markdown):
    {
      "Motivation": [
        {"q": "â€¦?", "help": "â€¦"},
        {"q": "â€¦?", "help": "â€¦"}
      ],
      "Energy & Resilience": [ â€¦ ],
      ...
    }
    """
    if "dynamic_qs" in st.session_state:
        return st.session_state["dynamic_qs"]         # already fetched

    client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
    past_context = build_past_context(user_email)

    system = ("You are an upbeat career-growth coach. "
              "Generate exactly two fresh reflection questions *per* category "
              "and a brief â€˜helpâ€™ tip that nudges the user to answer more deeply. "
              "Return only valid JSON following the given schema.")

    user_prompt = f"""
PAST ANSWERS
------------
{past_context}

CATEGORIES (keep order & names exactly):
{list(canvas_qs_pool.keys())}

Please comply with the schema."""
    response = client.chat.completions.create(
        model="o3",
        messages=[{"role": "system", "content": system},
                  {"role": "user", "content": user_prompt}],
        temperature=0.8
    )
    qs_json = json.loads(response.choices[0].message.content)
    st.session_state["dynamic_qs"] = qs_json
    return qs_json

# ðŸŽ¯ Playful growth-mindset question pool
canvas_qs_pool = {
    "Motivation": [
        "What tiny thing still lights a spark in you?",
        "If your life had a trailer, what scene would you keep in?",
        "Whatâ€™s keeping you curious lately?",
        "When did you last feel like, â€˜heck yes!â€™?",
        "What would you do tomorrow even if no one noticed?"
    ],
    "Energy & Resilience": [
        "Are you running on espresso, fumes, or vibes?",
        "Whatâ€™s been your emotional battery percentage this week?",
        "What people, snacks, or activities recharge you?",
        "What's been draining your inner superhero powers?",
        "If you had a â€˜low energyâ€™ warning light, would it be on?"
    ],
    "Support Systems": [
        "Whoâ€™s your ride-or-die this week?",
        "If you had a lifeline, who would you call?",
        "Any unsung heroes you want to thank?",
        "Are you asking for help or trying to solo everything?",
        "Who deserves a coffee for being there?"
    ],
    "Growth Mindset": [
        "Whatâ€™s something new you messed up â€” and learned from?",
        "When did you last surprise yourself?",
        "Where are you quietly leveling up?",
        "Any feedback you dodged (but kind of needed)?",
        "What's one awkward thing youâ€™re doing to grow?"
    ],
    "Vision": [
        "What would â€˜Level 2â€™ of your life look like?",
        "Even without the full map, whatâ€™s the next step?",
        "What future version of you would fist bump you today?",
        "What are you daydreaming about these days?",
        "If your purpose was a playlist, what song just got added?"
    ]
}

# ðŸ“ Contextual help for each question
canvas_help = {
    "What tiny thing still lights a spark in you?": "Think small â€” even a funny meme, warm tea, or unfinished idea counts.",
    "If your life had a trailer, what scene would you keep in?": "What recent moment felt â€˜so youâ€™ or gave your story momentum?",
    "Whatâ€™s keeping you curious lately?": "Name anything you keep coming back to â€” a topic, project, mystery.",
    "When did you last feel like, â€˜heck yes!â€™?": "Capture a moment of alignment, excitement, or even wild spontaneity.",
    "What would you do tomorrow even if no one noticed?": "What action would still feel worthwhile â€” even in secret?",

    "Are you running on espresso, fumes, or vibes?": "Be honest â€” your internal battery status matters more than your to-do list.",
    "Whatâ€™s been your emotional battery percentage this week?": "Try a number or describe it: charged, drained, blinking red?",
    "What people, snacks, or activities recharge you?": "List your go-to power-ups â€” silly, serious, or unexpected.",
    "What's been draining your inner superhero powers?": "Where have you been leaking energy, even subtly?",
    "If you had a â€˜low energyâ€™ warning light, would it be on?": "Any warning signs youâ€™ve been trying to ignore?",

    "Whoâ€™s your ride-or-die this week?": "Whoâ€™s shown up for you â€” practically or emotionally?",
    "If you had a lifeline, who would you call?": "Think of someone who makes you feel safer or stronger.",
    "Any unsung heroes you want to thank?": "Mention the folks who helped you (even without knowing it).",
    "Are you asking for help or trying to solo everything?": "Have you been open or secretly juggling it all?",
    "Who deserves a coffee for being there?": "Who showed up in a way you want to acknowledge?",

    "Whatâ€™s something new you messed up â€” and learned from?": "Own the goof â€” and the wisdom you squeezed from it.",
    "When did you last surprise yourself?": "Describe a moment that made you think, â€˜Whoa, did I just do that?â€™",
    "Where are you quietly leveling up?": "Even if no one sees it â€” where are you growing?",
    "Any feedback you dodged (but kind of needed)?": "Time to admit it â€” what feedback still lingers?",
    "What's one awkward thing youâ€™re doing to grow?": "Growth is often messy â€” name your current beautiful mess.",

    "What would â€˜Level 2â€™ of your life look like?": "Paint a picture of your next evolution â€” vague is okay.",
    "Even without the full map, whatâ€™s the next step?": "Tiny moves forward count. What feels like progress today?",
    "What future version of you would fist bump you today?": "Who are you becoming â€” and would they be proud?",
    "What are you daydreaming about these days?": "Fantasies and vague pulls often signal buried desires.",
    "If your purpose was a playlist, what song just got added?": "Pick a vibe or track that reflects your current direction."
}

def ask_questions():
    answers = {}
    user_email = st.session_state.get("user_email", "")
    dynamic_qs = fetch_dynamic_qs_openai(user_email)

    for section, qa_pairs in dynamic_qs.items():
        st.markdown(f"#### {section}")
        answers[section] = []
        for obj in qa_pairs:                # obj = {"q": ..., "help": ...}
            q = obj["q"]
            help_txt = obj.get("help", "")
            answers[section].append(
                st.text_area(
                    q,
                    key=q, max_chars=500,
                    placeholder=help_txt,
                    help=help_txt
                )
            )
    return answers

def get_dynamic_questions_once():
    if "dynamic_qs" not in st.session_state:
        st.session_state["dynamic_qs"] = {
            section: random.sample(questions, 2)
            for section, questions in canvas_qs_pool.items()
        }
    return st.session_state["dynamic_qs"]

def ask_questions():
    answers = {}
    dynamic_qs = get_dynamic_questions_once()
    for section, questions in dynamic_qs.items():
        st.markdown(f"#### {section}")
        answers[section] = [
            st.text_area(
                q,
                key=q,
                max_chars=500,
                placeholder=canvas_help.get(q, "Just be honest â€” even rough thoughts count."),
                help=canvas_help.get(q, "")
            ) for q in questions
        ]
    return answers

def build_image_prompt(insights: str) -> str:
    return f"""
Create a clean, flat-style digital illustration that clearly represents a personalized coaching action plan.
Purpose: The image should help the user **visually recall** and **stay motivated to follow** their action plan.

The image should:
- Depict 3 key steps based on the actions from these coaching suggestions: {insights}
- Show these steps as a vertical or horizontal sequence, like a roadmap or flow
- For each step, include a symbolic scene   
- Use realistic or symbolic visuals only 
- Strictly avoid any form of written or typographic characters. Do not include letters, numbers, signs, or symbolic text.
- Style: Flat illustration, warm tone, soft colors

"""


def generate_openai_feedback(canvas_answers: dict) -> tuple[int, str]:
    client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

    # Prepare current embedding
    current_text = " ".join(ans for section in canvas_answers.values() for ans in section)
    current_embedding = generate_embedding(current_text)

    # Load past check-ins with embeddings
    user_email = st.session_state.get("user_email", "")
    df = load_user_checkins(user_email)
    context_snippets = []

    if df is not None and "embedding_vector" in df.columns:
        embedding_tuples = [(i, vec) for i, vec in enumerate(df["embedding_vector"]) if vec is not None]
        if embedding_tuples:
            row_indices, vectors = zip(*embedding_tuples)
            top_indices = get_top_similar_checkins(current_embedding, list(vectors))
            for rel_idx in top_indices:
                idx = row_indices[rel_idx]
                row = df.iloc[idx]
                row_text = " | ".join(str(row.get(f"{section} Q{i}")) for section in canvas_qs_pool for i in [1, 2])
                context_snippets.append(f"{row['date']}: {row_text}")

    context_block = "\n".join(context_snippets[:3])

    flat_responses = []
    for category, responses in canvas_answers.items():
        joined = " | ".join(responses)
        flat_responses.append(f"{category}: {joined}")
    flat_response_block = "\n".join(flat_responses)

    prompt = f"""
You are a professional human coach known for being insightful, and practical.
Act as a tough, no-nonsense career coach specifically for professionals looking to grow. Avoid fluff and provide clear, direct, and actionable guidance. Pushe users hard, be brutally honest, and avoid sugar-coating advice. 
Focus on practical strategies, filling skill gaps, developing personal branding and networking plans. 
The tone is sharp, businesslike, and mirrors the precision of an executive coachâ€”focused on results, accountability, and professional growth.
Encourage progress, speak like a trusted coach who believes in the user's potential.
Use clear, concise language.

The user has completed a new check-in. Use the past check-in context below to enrich your understanding of patterns and history.

Past Check-In Context:
{context_block}

New Check-In:
{flat_response_block}

Your task is to:
1. Thoughtfully analyze the current responses
2. Assign a score from 1 to 25 based on:
   - Emotional clarity
   - Depth of self-awareness
   - Intentionality
   - Growth-oriented thinking
   
3. Provide a short justification for the score

4. Share 3 concise, actionable coaching suggestions (max 12 words each) - 1 for immediate, 1 for near-term (3 months), and 1 for long-term (6 months).

5. Summarize their overall theme or growth direction in one line

Format:
Score: <number>
Explanation: <brief explanation>
Actions:
- <Actionable suggestion 1> (max 12 words)
- <Actionable suggestion 2>
- <Optional suggestion 3>
Theme: <1-line theme>
"""

    try:
        response = client.chat.completions.create(
            #model="gpt-4o",
            model="o3",
            messages=[
                {"role": "system", "content": "You are a wise and supportive human coach."},
                {"role": "user", "content": prompt}
            ],
            temperature=1,
        )
        content = response.choices[0].message.content.strip()
        score_line = next((line for line in content.splitlines() if line.startswith("Score:")), "")
        score = int("".join([c for c in score_line if c.isdigit()])) if score_line else 0
        return score, content
    except Exception as e:
        return 0, f"âš ï¸ OpenAI Error: {str(e)}"


def generate_image_from_prompt(prompt_text: str) -> str:
    try:
        client = openai.OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
        response = client.images.generate(
            model="dall-e-3",
            prompt=prompt_text,
            n=1,
            size="1024x1024"
        )
        return response.data[0].url
    except Exception as e:
        st.error(f"âŒ Image generation failed: {e}")
        return ""



from PIL import Image, ImageDraw, ImageFont
import requests
from io import BytesIO

def overlay_coaching_text(image_url: str, action_items: list[str]) -> Image.Image:

    # Parse coaching suggestions
    #lines = [line.strip("- ").strip() for line in insights.splitlines() if line.strip().startswith("-")]
    lines = action_items

    # Load image
    response = requests.get(image_url)
    img = Image.open(BytesIO(response.content)).convert("RGBA")

    draw = ImageDraw.Draw(img)
    width, height = img.size

    # Try to load a clean font
    try:
        font = ImageFont.truetype("arial.ttf", size=28)
    except:
        font = ImageFont.load_default()

    # Draw background strip at top
    overlay = Image.new("RGBA", img.size, (255,255,255,0))
    overlay_draw = ImageDraw.Draw(overlay)
    overlay_draw.rectangle([0, 0, width, 40 + 35 * len(lines)], fill=(255, 255, 255, 220))  # White strip

    # Draw each line
    y = 20
    for line in lines:
        overlay_draw.text((30, y), line, font=font, fill=(0, 0, 0, 255))  # Black text
        y += 35

    # Combine
    combined = Image.alpha_composite(img, overlay)

    return combined.convert("RGB")


def show_insights(df):
    import matplotlib.pyplot as plt
    from datetime import datetime, timedelta
    import matplotlib.dates as mdates

    st.subheader("ðŸ“Š Check-In Score Summary")

    if "date" in df.columns and "score" in df.columns:
        df["date"] = pd.to_datetime(df["date"], errors="coerce")
        df["score"] = pd.to_numeric(df["score"], errors="coerce")
        df = df.sort_values("date")

        # User selection for timeframe
        timeframe = st.selectbox("Show scores for:", ["Last 7 days", "Last 14 days", "Last 30 days", "All time"])
        days_map = {
            "Last 7 days": 7,
            "Last 14 days": 14,
            "Last 30 days": 30,
            "All time": None
        }
        days = days_map[timeframe]
        if days:
            cutoff_date = datetime.now().date() - timedelta(days=days)
            df_filtered = df[df["date"].dt.date >= cutoff_date]
        else:
            df_filtered = df

        # Plot
        fig, ax = plt.subplots(figsize=(12, 4))
        ax.plot(df["date"], df["score"], marker='o', linestyle='-', color='gray', alpha=0.3, label="All scores")
        ax.plot(df_filtered["date"], df_filtered["score"], marker='o', linestyle='-', color='blue', label=f"{timeframe}")

        # Threshold lines
        ax.axhline(y=10, color='red', linestyle='--', linewidth=1, label='Needs Attention (<10)')
        ax.axhline(y=20, color='green', linestyle='--', linewidth=1, label='Excellent (â‰¥20)')

        ax.set_ylim(1, 25)
        ax.set_title("Check-In Score Summary")
        ax.set_xlabel("Date")
        ax.set_ylabel("Score (1â€“25)")

        # Format x-axis
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))
        fig.autofmt_xdate(rotation=45)

        ax.grid(True)
        ax.legend()
        st.pyplot(fig)

    # Coaching recommendation
    if "recommendation" in df.columns and not df["recommendation"].isnull().all():
        latest = df.sort_values("date").iloc[-1]
        st.subheader("ðŸ§  Last Coaching Recommendation")
        st.markdown(latest["recommendation"])

    # Full data table
    with st.expander("ðŸ“‹ Show full check-in details"):
        st.dataframe(
            df.sort_values(by="date", ascending=False).style.format({"date": lambda d: d.strftime("%Y-%m-%d")}),
            use_container_width=True,
            height=300
        )




def get_demo_checkins(selected_email):
    df = get_all_checkins()
    if df is not None and not df.empty:
        password = st.session_state.get("user_password", "")
        df["user_decrypted"] = df["user"].apply(lambda val: decrypt_checkin(val, password, selected_email))
        df = df[df["user_decrypted"] == selected_email]
        for col in df.columns:
            if col in ("user", "score", "recommendation", "date") or "Q" in col:
                df[col] = df[col].apply(lambda val: decrypt_checkin(val, password, selected_email) if val else "")
        return df
    return pd.DataFrame()

def show_demo_coaching(selected_email):
    if selected_email == "alex@example.com":
        st.markdown("### Alex (alex@example.com)")
        st.markdown("- ðŸ§  **Stretch into a Leadership Role**  \nAlex is consistently performing at a high level and showing signs of sustained motivation and support. Taking on leadership can help channel their energy into multiplying impact.")
        st.markdown("- ðŸŒ± **Experiment with New Challenges**  \nTo avoid plateauing, Alex should seek out stretch assignments or novel tasks that demand new skills and perspectives.")
        st.markdown("- ðŸ§˜ **Invest in Recovery Rituals**  \nWhile high performing, the data hints at intense engagement that could lead to burnout. Small rituals like nature walks or journaling can enhance long-term resilience.")
    elif selected_email == "jamie@example.com":
        st.markdown("### Jamie (jamie@example.com)")
        st.markdown("- ðŸ› ï¸ **Build a Resilience Routine**  \nJamieâ€™s entries show signs of moderate motivation but inconsistent energy. Introducing small, daily recovery habits can help maintain momentum.")
        st.markdown("- ðŸ” **Clarify a Meaningful Short-Term Goal**  \nThe text shows a drift in purpose. Setting a concrete 2-week target can reinstate direction and reduce emotional fatigue.")
        st.markdown("- ðŸ¤ **Expand Support Circle**  \nSupport system references are sparse. Encouraging Jamie to proactively reconnect with peers or mentors can stabilize emotional load.")
    elif selected_email == "morgan@example.com":
        st.markdown("### Morgan (morgan@example.com)")
        st.markdown("- ðŸ›Œ **Permission to Rest**  \nMorganâ€™s check-ins point to exhaustion and demotivation. Before any change, recovery needs to be prioritized â€” guilt-free rest is valid and necessary.")
        st.markdown("- ðŸ§© **Reconnect to Core Values**  \nThe text shows signs of identity disconnection. Reflecting on why certain things matter can re-anchor purpose and self-worth.")
        st.markdown("- ðŸ”¦ **Find Micro-Moments of Joy**  \nMorgan should be encouraged to note 1â€“2 tiny joys per day. Building emotional scaffolding from joy is a proven recovery tool.")
    else:
        st.warning("No coaching suggestions available.")




def generate_embedding(text: str) -> list[float]:
    client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
    response = client.embeddings.create(
        input=text,
        model="text-embedding-3-small"
    )
    return response.data[0].embedding


def get_top_similar_checkins(current_embedding, past_embeddings, top_k=3):
    if not past_embeddings:
        return []
    sims = cosine_similarity([current_embedding], past_embeddings)[0]
    top_indices = np.argsort(sims)[-top_k:][::-1]
    return top_indices


# Modify save_checkin to include embedding

def save_checkin(user_email, canvas_answers, score, recommendation=None):
    password = st.session_state.get("user_password", "")
    now_str = datetime.now().strftime("%Y-%m-%d %H:%M")
    flat_text = " ".join(ans for section in canvas_answers.values() for ans in section)
    embedding = generate_embedding(flat_text)

    entry = {
        "date": encrypt_checkin(now_str, password, user_email),
        "user": encrypt_checkin(user_email, password, user_email),
        "score": encrypt_checkin(str(score), password, user_email),
        "recommendation": encrypt_checkin(recommendation or "", password, user_email),
        "embedding": json.dumps(embedding)
    }
    for section, answers in canvas_answers.items():
        entry[f"{section} Q1"] = encrypt_checkin(answers[0], password, user_email)
        entry[f"{section} Q2"] = encrypt_checkin(answers[1], password, user_email)
    append_checkin_to_sheet(entry)


# Modify load_user_checkins to extract embeddings

def load_user_checkins(user_email):
    df = get_all_checkins()
    if df is not None and not df.empty:
        password = st.session_state.get("user_password", "")
        df["user_decrypted"] = df["user"].apply(lambda val: decrypt_checkin(val, password, user_email))
        df = df[df["user_decrypted"] == user_email]
        for col in df.columns:
            if col in ("user", "score", "recommendation", "date") or "Q" in col:
                df[col] = df[col].apply(lambda val: decrypt_checkin(val, password, user_email) if val else "")
        if "embedding" in df.columns:
            df["embedding_vector"] = df["embedding"].apply(lambda x: json.loads(x) if x and x.strip().startswith("[") else None)
        return df
    return None



def reflect_on_last_action(df):
    if df is not None and not df.empty:
        latest = df.sort_values("date").iloc[-1]
        last_reco = latest.get("recommendation", "")
        st.info("ðŸ“Œ Here's a reminder of your last coaching action plan:")
        st.markdown(last_reco)

        rating = st.slider(
            "How well were you able to follow through with this?",
            min_value=1,
            max_value=5,
            value=3,
            format="%d ðŸŒŸ"
        )

        st.session_state["last_action_rating"] = rating
